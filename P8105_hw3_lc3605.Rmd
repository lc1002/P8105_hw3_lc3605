---
title: "P8105_hw3_lc3605"
author: "Lynn Chen"
output: github_document
---

```{r setup}
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(p8105.datasets)
library(patchwork)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1: 

Load `instacart` data 

```{r}
data("instacart")
```

The **instacart** dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. The data contains the following variables: **`r ls(instacart)`**; and each row in the dataset represents products ordered. 
In total, there are `r instacart %>% select(product_id) %>% distinct() %>% count()` products found in `r instacart %>% select(user_id, order_id) %>% distinct() %>% count()` orders, and `r instacart %>% select(user_id) %>% distinct() %>% count()` distinct users who made a purchase.

* How many aisles are there, and which aisles are the most items ordered from?

```{r, message = FALSE, collapse = TRUE}
instacart %>% 
  summarize(n_aisles = n_distinct(aisle_id))
  
instacart %>% 
  group_by(aisle) %>% 
  summarize(most_order = n()) %>% 
  arrange(desc(most_order)) %>% 
  top_n(3)
```
There are **`r instacart %>% select(aisle_id) %>% distinct() %>% count()`** aisles in total. The top 3 aisles with most items ordered are **fresh vegetables, fresh fruits, and packaged vegetables fruits**. 


* Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart %>%
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
	geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.3, hjust = 1), 
        plot.title = element_text(hjust = 0.5)) + 
  labs(
    title = "Number of items ordered",
    x = "Aisles",
    y = "Number of items"
  )
```


* Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank <= 3) %>% 
  arrange(aisle, rank) %>%
  select(-rank, most_popular_items = product_name, number_of_items = n) %>% 
  knitr::kable()
```
In aisle **baking ingredients**, the most popular item was "Light Brown Sugar", which had been ordered 499 times.

In aisle **dog food care**, the most popular item was "Snack Sticks Chicken & Rice Recipe Dog Treats", which had been ordered 30 times.

In aisle **packaged vegetables fruits**, the most popular item was "Organic Baby Spinach", which had been ordered 9784 times.


* Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r, message = FALSE}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  mutate(
    order_dow = recode(order_dow,`0` = "Sun", `1` = "Mon", `2` = "Tue", `3` = "Wed", `4` = "Thr", `5` = "Fri", `6` = "Sat")) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>%
  knitr::kable(digits = 2)
```


## Problem 2:

Load and clean the `BRFSS` data.

```{r load brfss data}
data("brfss_smart2010")
```

First, data cleaning:

```{r data cleaning for brfss}
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health",
    response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>% 
  mutate(response = as.factor(response),
         response = ordered(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  select(year, locationdesc, topic, response, data_value, sample_size) %>%
  separate(locationdesc, into = c("state", "county"), sep = " - ")
```

Several questions to answer:

* In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
brfss_df_2002 = 
  brfss_df %>% 
  group_by(state) %>% 
  filter(year == "2002") %>%
  distinct(county) %>%
  count(state) %>% 
  filter(n >= 7)

brfss_df_2010 = 
  brfss_df %>% 
  group_by(state) %>% 
  filter(year == "2010") %>%
  distinct(county) %>%
  count(state) %>% 
  filter(n >= 7)
```

In 2002, states **CT, FL, MA, NC, NJ, PA** were observed at 7 or more locations.

In 2010, 14 states were observed at 7 or more locations: **CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA**.

* Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. 

```{r excellent response}
excellent_df = 
  brfss_df %>%
  filter(response == "Excellent") %>% 
  group_by(state, year) %>% 
  mutate(mean_data_value = mean(data_value, na.rm = TRUE),
         mean_data_value = round(mean_data_value, digits = 2)) %>%
  select(year, state, mean_data_value) 
```

* Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).

```{r spaghetti plot, warning = FALSE, message = FALSE}
brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year, state) %>%
  summarize(mean_value = mean(data_value), na.rm = TRUE) %>% 
  ggplot(aes(x = year, y = mean_value, group = state, color = state)) +
  geom_line() +
  theme_bw() +
  labs(
    title = "Average Value overtime in each state",
    x = "Year",
    y = "Average value")
```


* Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r two panel plot}
brfss_df %>%
  filter(year == "2006" | year == "2010",
         state == "NY") %>% 
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
labs(
    title = "Distribution of data values for year 2006 & 2010 by response in NY",
    x = "Response",
    y = "Data Value"
  )
```


## Problem 3: 

Load, tidy, the `accelerometer` data. 

```{r, message = FALSE}
accel_df = 
  read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = "activity_minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>%
  mutate(
    activity_minute = as.integer(activity_minute),
    weekday_or_weekend = ifelse(day %in% c("Saturday","Sunday"), "Weekend", "Weekday"),
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  arrange(day) 
```

The **accelometer** dataset contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. Variables include in the data are **`r ls(accel_df)`**. The dataset provides five-week observations on "activity counts" of a 63 year-old male with BMI 25. The counting started at the midnight of each day with one-minute intervals. Also, in order to distinguish between weekdays and weekends, `weekday_or_weekend` was created.

 
* Create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?

```{r}
accel_df %>%
  group_by(day, week) %>% 
  summarize(total_activity = sum(activity_count)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "total_activity"
  ) %>% 
  knitr::kable(digits = 0)
```

According to the resulting table, this man tends to have a stable level of activity over weekdays with Monday being less active than other weekdays in the first two weeks. There is extremely low activity levels on the Saturday of week 4 and 5.


* Make a single-panel plot that shows the 24-hour activity time courses for each day.

```{r, message = FALSE}
accel_df %>% 
  ggplot(aes(x = activity_minute, y = activity_count)) + 
  geom_line(aes(color = day)) +
  labs(y = "Total Activity (min)", x = "Day", title = "24-hour activity time of 63 year-old male")





## covert activity minutes to hours and plot  
accel_df %>% 
  mutate(hour = round(activity_minute/60)) %>% 
  group_by(day, hour) %>% 
  summarize(hourly_activity = mean(activity_count)) %>% 
  ggplot(aes(x = hour, y = hourly_activity, color = day)) + 
  geom_line() +
  geom_point(size = 1.5) +
  scale_x_continuous(name = "Hour", breaks = seq(0, 24, by = 2)) +
  labs(
    title = "24 hour activity time of 63 year-old male",
    x = "Hour",
    y = "Activity",
    color = "Day of the Week"
  )
```

The plot shows that the man is more active at night (Around 20:00 to 22:00) and less active at midnight during sleeping hours from 23:00 to 6:00AM. On weekdays, Tuesday, Wednesday, Thursday has roughly a steady trend, but on Friday, Sunday, and Monday has a more fluctuating trend with a peak. The two largest peaks belong to Sundays between 9 and 13 and Fridays between 21 and 23. Generally, the man is more active during weekdays than weekends. 


